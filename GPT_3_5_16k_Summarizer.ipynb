{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR6ag72qRGfDEDxtYuO7Fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawkintrevo/ai-summaries/blob/main/GPT_3_5_16k_Summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai -q\n",
        "!pip install --upgrade tiktoken -q\n",
        "!pip install GitPython -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap23xi1hiEKm",
        "outputId": "f3389983-fd2a-4d29-f836-b5ec9959d20f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXWdrdJogjWB"
      },
      "outputs": [],
      "source": [
        "OPEN_AI_KEY = \"\"\n",
        "GITHUB_TOKEN = \"\"\n",
        "INPUT_DIR = \"\"\n",
        "TITLE=\"\"\n",
        "REFERENCE_LINK = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import tiktoken\n",
        "from datetime import datetime\n",
        "\n",
        "openai.api_key = OPEN_AI_KEY\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peKa9orahMEH",
        "outputId": "4442a768-ed6c-4b08-ee57-e11b24e6f05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_string(string: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "\n",
        "def summarize(text, long_text=False):\n",
        "  model=\"gpt-3.5-turbo\"\n",
        "  if long_text:\n",
        "    model=\"gpt-3.5-turbo-16k\"\n",
        "  print(f\"Using Model: {model}\")\n",
        "  completion = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=[\n",
        "      {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"Summarize content you are provided in great detail (at least 600 words, up to 2000 words).\"\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": text\n",
        "      }])\n",
        "  return completion.choices[0].message.content\n",
        "\n",
        "def clone_repo(GITHUB_TOKEN):\n",
        "  from git import Repo\n",
        "  HTTPS_REMOTE_URL = f'https://{GITHUB_TOKEN}:x-oauth-basic@github.com/rawkintrevo/ai-summaries'\n",
        "  repo = Repo.clone_from(HTTPS_REMOTE_URL, \"ai-summaries\")\n",
        "  return repo\n",
        "\n",
        "def summarize_file(fname):\n",
        "  with open(f\"{INPUT_DIR}/{fname}\", 'r') as f:\n",
        "    content = f.read()\n",
        "  long_text = False\n",
        "  if num_tokens_from_string(content) > 4000:\n",
        "    long_text = True\n",
        "  summary = summarize(content, long_text)\n",
        "  return summary\n",
        "\n",
        "def write_file(git_dir, summary, fname):\n",
        "  header = f\"\"\"---\n",
        "layout: page\n",
        "title: {fname.replace('.txt','')}\n",
        "date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "---\n",
        "\"\"\"\n",
        "  with open(f\"{git_dir}/{fname.replace('.txt','.md')}\", 'w') as f:\n",
        "    f.write(header + summary + f\"\\n\\nWords: {len(summary.split())}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lrx-AoIeingm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "files_to_summarize = [f for f in listdir(INPUT_DIR) if f.endswith(\".txt\")]\n",
        "\n",
        "files_to_summarize.sort()\n",
        "\n",
        "files_to_add = []\n",
        "\n",
        "# repo = clone_repo(GITHUB_TOKEN)\n",
        "\n",
        "output_dir = ''.join(c for c in TITLE if c.isalnum()).lower()\n",
        "\n",
        "repo = clone_repo(GITHUB_TOKEN)\n",
        "\n",
        "from os import mkdir\n",
        "mkdir(f\"ai-summaries/summaries/{output_dir}\")\n",
        "\n",
        "for fname in files_to_summarize:\n",
        "  print(f\"Summarizing: {fname}\")\n",
        "  summary = summarize_file(fname)\n",
        "  write_file(f\"ai-summaries/summaries/{output_dir}\", summary, fname)\n",
        "  files_to_add.append(f\"summaries/{output_dir}/{fname.replace('.txt','.md')}\")\n",
        "\n",
        "\n",
        "links = \"\\n* \".join([f\"[{name.replace('.txt','')}]({name.replace('.txt','.html')})\" for name in files_to_summarize])\n",
        "index_page = f\"\"\"---\n",
        "layout: page\n",
        "title: {TITLE}\n",
        "date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "---\n",
        "\n",
        "[Source]({REFERENCE_LINK})\n",
        "\n",
        "## Parts\n",
        "* {links}\"\"\"\n",
        "\n",
        "print(\"writing index page\")\n",
        "with open(f\"ai-summaries/summaries/{output_dir}/index.md\", 'w') as f:\n",
        "  f.write(index_page)\n",
        "\n",
        "files_to_add.append(f\"summaries/{output_dir}/index.md\")\n",
        "\n",
        "print(\"adding entry to top index\")\n",
        "markdown_link = f\"[{TITLE}](summaries/{output_dir}/index.html)\\n\"\n",
        "with open(\"ai-summaries/index.markdown\", \"a\") as file:\n",
        "    file.write(markdown_link)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL6m3DMziMNm",
        "outputId": "45a69289-134b-4884-be4b-453cea5360f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarizing: ch01.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "Summarizing: ch02.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "Summarizing: ch03.txt\n",
            "Using Model: gpt-3.5-turbo\n",
            "Summarizing: ch04.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "Summarizing: ch06.txt\n",
            "Using Model: gpt-3.5-turbo\n",
            "Summarizing: ch07.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "Summarizing: ch08.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "Summarizing: ch09.txt\n",
            "Using Model: gpt-3.5-turbo\n",
            "Summarizing: ch10.txt\n",
            "Using Model: gpt-3.5-turbo\n",
            "Summarizing: ch11.txt\n",
            "Using Model: gpt-3.5-turbo\n",
            "Summarizing: ch12.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "Summarizing: ch13.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "Summarizing: ch14.txt\n",
            "Using Model: gpt-3.5-turbo\n",
            "Summarizing: ch15.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "Summarizing: ch16.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "Summarizing: ch17.txt\n",
            "Using Model: gpt-3.5-turbo-16k\n",
            "writing index page\n",
            "adding entry to top index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_to_add += [\"index.markdown\", f\"summaries/{output_dir}/index.md\"]\n",
        "for f in files_to_add:\n",
        "  print(f\"Adding {f}\")\n",
        "  repo.index.add(f.replace(\"ai-summaries/\", \"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzSm3ZHVisR2",
        "outputId": "deefad13-4d42-44ff-a92b-d3d1595d51c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding summaries/federalcontractingmadeeasy4thedition/ch01.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch02.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch03.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch04.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch06.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch07.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch08.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch09.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch10.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch11.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch12.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch13.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch14.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch15.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch16.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/ch17.md\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/index.md\n",
            "Adding index.markdown\n",
            "Adding summaries/federalcontractingmadeeasy4thedition/index.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo.index.commit(TITLE)\n",
        "origin = repo.remote(name='origin')\n",
        "origin.push()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE0JLZ8M6qlY",
        "outputId": "8e31d308-41bc-4622-b77e-6dc43eece4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<git.remote.PushInfo at 0x7bc0deb8b330>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8NWglBtN_k7f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}